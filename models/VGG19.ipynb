{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOePZ5UqlGLQxay5YnRSPp6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##VGG19 model for FeelBeat with FER dataset"],"metadata":{"id":"yxfwAlIHMQjM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"10GnHXyHLys9"},"outputs":[],"source":["!pip install keras-application"]},{"cell_type":"code","source":["!pip install scikit-image\n","!pip install pydot\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMBc4pACMF1T","executionInfo":{"status":"ok","timestamp":1699184519315,"user_tz":-360,"elapsed":8980,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}},"outputId":"962c1c97-ef3d-41e4-be0e-63146cc5f30c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.23.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.3)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.1)\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.python.lib.io import file_io\n","\n","import keras\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.models import load_model\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import plot_model\n","from sklearn.metrics import *\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.models import Model\n","from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n","import skimage\n","from skimage.transform import rescale, resize\n","\n","import pydot"],"metadata":{"id":"Dz5P5d_aMQJa","executionInfo":{"status":"ok","timestamp":1699184523564,"user_tz":-360,"elapsed":4257,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcKc9rgjMar5","executionInfo":{"status":"ok","timestamp":1699184538787,"user_tz":-360,"elapsed":15228,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}},"outputId":"2ed50172-d415-4683-8391-954a5b53177d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u88DZmK5O7ZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 100\n","BS = 128\n","DROPOUT_RATE = 0.5\n","FROZEN_LAYER_NUM = 19\n","\n","ADAM_LEARNING_RATE = 0.001\n","SGD_LEARNING_RATE = 0.01\n","SGD_DECAY = 0.0001\n","\n","Resize_pixelsize = 197"],"metadata":{"id":"gIVcaZTCMdHX","executionInfo":{"status":"ok","timestamp":1699184538787,"user_tz":-360,"elapsed":2,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["vgg19_notop = VGG19(include_top =False,weights='imagenet',input_shape =(Resize_pixelsize, Resize_pixelsize,3), pooling='avg')\n","print(vgg19_notop.summary())\n","last_layer = vgg19_notop.get_layer('block4_pool').output\n","x = Flatten(name='flatten')(last_layer)\n","x = Dropout(DROPOUT_RATE)(x)\n","x = Dense(4096, activation ='relu', name='fc6')(x)\n","x = Dropout(DROPOUT_RATE)(x)\n","x = Dense(1024, activation='relu', name='fc7')(x)\n","\n","for i in range(FROZEN_LAYER_NUM):\n","    vgg19_notop.layers[i].trainable = False\n","\n","print(vgg19_notop.get_layer('block4_pool').trainable)\n","\n","out = Dense(7, activation='softmax', name='classifier')(x)\n","\n","model = Model(vgg19_notop.input, out)\n","\n","\n","sgd = tf.keras.optimizers.legacy.SGD(learning_rate=SGD_LEARNING_RATE, momentum=0.9, decay=SGD_DECAY, nesterov=True)\n","rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_acc',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n","callbacks_list = [rlrop]\n","\n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n"],"metadata":{"id":"iQ2uuX7ZMfd5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699184542757,"user_tz":-360,"elapsed":771,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}},"outputId":"2db6acd3-cdfd-4558-e2f7-ccd0a426d68f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80134624/80134624 [==============================] - 0s 0us/step\n","Model: \"vgg19\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 197, 197, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 197, 197, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 197, 197, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 98, 98, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 98, 98, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 98, 98, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 49, 49, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 49, 49, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 49, 49, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 49, 49, 256)       590080    \n","                                                                 \n"," block3_conv4 (Conv2D)       (None, 49, 49, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 24, 24, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 24, 24, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 24, 24, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 24, 24, 512)       2359808   \n","                                                                 \n"," block4_conv4 (Conv2D)       (None, 24, 24, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n","                                                                 \n"," block5_conv4 (Conv2D)       (None, 12, 12, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n","                                                                 \n"," global_average_pooling2d (  (None, 512)               0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n","=================================================================\n","Total params: 20024384 (76.39 MB)\n","Trainable params: 20024384 (76.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","False\n"]}]},{"cell_type":"code","source":["! rm -rf train; mkdir train\n","! unzip -q '/content/drive/MyDrive/CSE499A/Datasets/train.zip' -d train\n","! unzip -q '/content/drive/MyDrive/CSE499A/Datasets/ck_train.zip' -d train\n","! unzip -q '/content/drive/MyDrive/CSE499A/Datasets/ck+_train.zip' -d train\n","! unzip -q '/content/drive/MyDrive/CSE499A/Datasets/train_jaffe.zip' -d train\n","\n"],"metadata":{"id":"YonsqZbhPLbm","executionInfo":{"status":"ok","timestamp":1699184546789,"user_tz":-360,"elapsed":3674,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["! rm -rf dev; mkdir dev\n","! unzip -q '/content/drive/MyDrive/CSE499A/Datasets/test-public.zip' -d dev\n","!rm -rf test; mkdir test\n","\n","! unzip -q '/content/drive/MyDrive/CSE499A/Datasets/test-private.zip' -d test"],"metadata":{"id":"TlikhvPhPQgN","executionInfo":{"status":"ok","timestamp":1699184548139,"user_tz":-360,"elapsed":1356,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","def get_datagen(dataset, aug=False):\n","    if aug:\n","        datagen = ImageDataGenerator(\n","                            rescale=1./255,\n","                            featurewise_center=False,\n","                            featurewise_std_normalization=False,\n","                            rotation_range=10,\n","                            width_shift_range=0.1,\n","                            height_shift_range=0.1,\n","                            zoom_range=0.1,\n","                            horizontal_flip=True)\n","    else:\n","        datagen = ImageDataGenerator(rescale=1./255)\n","\n","    return datagen.flow_from_directory(\n","            dataset,\n","            target_size=(197, 197),\n","            color_mode='rgb',\n","            shuffle = True,\n","            class_mode='categorical',\n","            batch_size=BS)"],"metadata":{"id":"ReJp-LfdPawE","executionInfo":{"status":"ok","timestamp":1699184548140,"user_tz":-360,"elapsed":4,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_generator  = get_datagen('/content/train', True)\n","dev_generator  = get_datagen('/content/dev')\n","test_generator  = get_datagen('/content/test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YbS7P-FxPdPt","executionInfo":{"status":"ok","timestamp":1699184548959,"user_tz":-360,"elapsed":823,"user":{"displayName":"Tanzim Farhan","userId":"16408072662315740322"}},"outputId":"0b9c41e3-bf99-4697-f471-fc429bb5733a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 30533 images belonging to 7 classes.\n","Found 3589 images belonging to 7 classes.\n","Found 3589 images belonging to 7 classes.\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","    x = train_generator,\n","    validation_data=test_generator,\n","    steps_per_epoch=28709// BS,\n","    validation_steps=3509 // BS,\n","    shuffle=True,\n","    epochs=EPOCHS,\n","    callbacks=callbacks_list,\n","    use_multiprocessing=True,\n",")"],"metadata":{"id":"YvhdTm8UPgZS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c83cf06-cf8c-4163-8a57-468bf7cda37e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","224/224 [==============================] - ETA: 0s - loss: 243943.6250 - accuracy: 0.2413"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/224 [==============================] - 357s 2s/step - loss: 243943.6250 - accuracy: 0.2413 - val_loss: 1.8330 - val_accuracy: 0.2471 - lr: 0.0100\n","Epoch 2/100\n","224/224 [==============================] - ETA: 0s - loss: 1.8307 - accuracy: 0.2463"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/224 [==============================] - 361s 2s/step - loss: 1.8307 - accuracy: 0.2463 - val_loss: 1.8189 - val_accuracy: 0.2483 - lr: 0.0100\n","Epoch 3/100\n","224/224 [==============================] - ETA: 0s - loss: 1.8304 - accuracy: 0.2462"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/224 [==============================] - 373s 2s/step - loss: 1.8304 - accuracy: 0.2462 - val_loss: 1.8169 - val_accuracy: 0.2442 - lr: 0.0100\n","Epoch 4/100\n"," 58/224 [======>.......................] - ETA: 4:19 - loss: 88.7787 - accuracy: 0.2485"]}]}]}